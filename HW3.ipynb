{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b57d11",
   "metadata": {
    "id": "b32ba0fd"
   },
   "source": [
    "# Fall 2023 Applied NLP Homework 3\n",
    "\n",
    "## Instructors: Dr. Mahdi Roozbahani, Wafa Louhichi, Dr. Nimisha Roy\n",
    "\n",
    "## Deadline: November 3rd, 11:59PM AoE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bbce98",
   "metadata": {
    "id": "eb689246"
   },
   "source": [
    "## Honor Code and Assignment Deadline\n",
    "<!-- No changes needed on the below section -->\n",
    "* No unapproved extension of the deadline is allowed. Late submission will lead to 0 credit. \n",
    "\n",
    "* Discussion is encouraged on Ed as part of the Q/A. However, all assignments should be done individually.\n",
    "\n",
    "* <font color='darkred'>Plagiarism is a **serious offense**. You are responsible for completing your own work. You are not allowed to copy and paste, or paraphrase, or submit materials created or published by others, as if you created the materials. All materials submitted must be your own.</font>\n",
    "\n",
    "* <font color='darkred'>All incidents of suspected dishonesty, plagiarism, or violations of the Georgia Tech Honor Code will be subject to the instituteâ€™s Academic Integrity procedures. If we observe any (even small) similarities/plagiarisms detected by Gradescope or our TAs, **WE WILL DIRECTLY REPORT ALL CASES TO OSI**, which may, unfortunately, lead to a very harsh outcome. **Consequences can be severe, e.g., academic probation or dismissal, grade penalties, a 0 grade for assignments concerned, and prohibition from withdrawing from the class.**\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b8413",
   "metadata": {
    "id": "18717a84"
   },
   "source": [
    "## Instructions for the assignment \n",
    "\n",
    "<!-- No changes needed on the below section -->\n",
    "- This entire assignment will be autograded through Gradescope. There are two Gradescope submissions for this assignment:\n",
    "    - **Homework 3**: Submit files for Q1 to Q3 to this section \n",
    "    - **Homework 3 - Bonus EC (Optional)**: Submit the Bonus Q4 file to this section\n",
    "\n",
    "- We provided you different .py files and we added libraries in those files please DO NOT remove those lines and add your code after those lines. Note that these are the only allowed libraries that you can use for the homework.\n",
    "\n",
    "- You will submit your implemented .py files to the corresponding homework section on Gradescope. \n",
    "\n",
    "- You are allowed to make as many submissions until the deadline as you like. Additionally, note that the autograder tests each function separately, therefore it can serve as a useful tool to help you debug your code if you are not sure of what part of your implementation might have an issue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626498e8",
   "metadata": {},
   "source": [
    "## Using the local tests <a id='using_local_tests'></a>\n",
    "- For some of the programming questions we have included a local test using a small toy dataset to aid in debugging. The local test sample data and outputs are stored in .py files in the **local_tests** folder\n",
    "- There are no points associated with passing or failing the local tests, you must still pass the autograder to get points. \n",
    "- **It is possible to fail the local test and pass the autograder** since the autograder has a certain allowed error tolerance while the local test allowed error may be smaller. Likewise, passing the local tests does not guarantee passing the autograder. \n",
    "- **You do not need to pass both local and autograder tests to get points, passing the Gradescope autograder is sufficient for credit.**\n",
    "- It might be helpful to comment out the tests for functions that have not been completed yet. \n",
    "- It is recommended to test the functions as it gets completed instead of completing the whole class and then testing. This may help in isolating errors. Do not solely rely on the local tests, continue to test on the autograder regularly as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87a5f0d",
   "metadata": {
    "id": "f3559faf"
   },
   "source": [
    "# Google Colab Setup (Optional for running on Colab)\n",
    "If you choose to work on the assignment on Google Colab, the following cell may help get you set up. You may need to right click on the Applied NLP folder and `Add shortcut to Drive`. You do not have to run this cell if you are working on the notebook locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ade04b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0066960d",
    "outputId": "ef5fd2e4-2d26-4f36-9115-3fcbbd7ec11e"
   },
   "outputs": [],
   "source": [
    "# # Mount google drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "# # You may need to create an Applied_NLP/HW#/hw#_code/ folder\n",
    "# %cd '/content/drive/MyDrive/Applied_NLP/HW#/hw#_code/'\n",
    "\n",
    "# ## If no GPU selected it will ask for GPU to be selected\n",
    "# gpu_info = !nvidia-smi\n",
    "# gpu_info = '\\n'.join(gpu_info)\n",
    "# if gpu_info.find('failed') >= 0:\n",
    "#   print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "#   print('and then re-execute this cell.')\n",
    "# else:\n",
    "#   print(gpu_info)\n",
    "\n",
    "\n",
    "# ## This wraps output text according to the window size\n",
    "# from IPython.display import HTML, display\n",
    "\n",
    "# def set_css():\n",
    "#   display(HTML('''\n",
    "#   <style>\n",
    "#     pre {\n",
    "#         white-space: pre-wrap;\n",
    "#     }\n",
    "#   </style>\n",
    "#   '''))\n",
    "# get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4a5d05",
   "metadata": {
    "id": "05409a58"
   },
   "source": [
    "# Assignment Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334bf877",
   "metadata": {
    "id": "89d96973"
   },
   "source": [
    "In this homework we will explore non-linear text classification algorithms : Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). We will also look into another embedding techique : Word2Vec.\n",
    "\n",
    "We will reuse the datasets from HW2 for this exploration:\n",
    "* The first dataset is a subset of a [Clickbait Dataset](https://github.com/bhargaviparanjape/clickbait/tree/master/dataset) that has article headlines and a binary label on whether the headline is considered clickbait. \n",
    "* The second dataset is a subset of [Web of Science Dataset](https://data.mendeley.com/datasets/9rw3vkcfy4/6) that has articles and a corresponding label on the domain of the articles. \n",
    "\n",
    "We will first explore Continuous Bag-of-Words (CBOW) and Skip-gram based Word2Vec models using a very small dataset. We will then use pre-trained Word2Vec embeddings and feed them to the classification algorithms.\n",
    "\n",
    "As a bonus exercise, you will have the opportunity to write your own training loop to train a simple two layer neural net.\n",
    "\n",
    "**You will be using pytorch for coding the models in this homework.** [Tutorial](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html) and [Building model](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html) are good references for those who are new to pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de75888",
   "metadata": {
    "id": "e51f68d8"
   },
   "source": [
    "## Deliverables and Points Distribution\n",
    "\n",
    "### Q1: Word2Vec [45pts]\n",
    "- **1.1 Implementing CBOW from Scratch** [26pts] Deliverables: <font color = 'green'>word2vec.py</font>\n",
    "\n",
    "    - [2pts] tokenize (Word2Vec class)\n",
    "\n",
    "    - [5pts] create_vocabulary (Word2Vec class)\n",
    "\n",
    "    - [10pts] cbow_embeddings (Word2Vec class)\n",
    "\n",
    "    - [4pts] \\_\\_init__ (CBOW_Model class)\n",
    "    \n",
    "    - [5pts] forward (CBOW_Model class)\n",
    "\n",
    "- **1.2 Implementing Skip-Gram from Scratch** [19pts] Deliverables: <font color = 'green'>word2vec.py</font>\n",
    "\n",
    "    - [10pts] skipgram_embeddings (Word2Vec class)\n",
    "\n",
    "    - [4pts] \\_\\_init__ (SkipGram_Model class)\n",
    "\n",
    "    - [5pts] forward (SkipGram_Model class)\n",
    "\n",
    "### Q2: Classification with CNN [15pts]\n",
    "- **2.1 Implementing CNN** [10pts] Deliverables: <font color = 'green'>cnn.py</font>\n",
    "\n",
    "    - [3pts] \\_\\_init__\n",
    "\n",
    "    - [7pts] forward\n",
    "        - [2pts] forward_embed\n",
    "        - [3pts] forward_convs\n",
    "        - [2pts] forward\n",
    "- **2.3: Classifying Web of Science Dataset using CNN** [5pts] Deliverables: <font color = 'green'>cnn.py and best_cnn_model.pt</font>\n",
    "\n",
    "### Q3: Classification with RNN [15pts]\n",
    "- **3.1 Implementing RNN** [10pts] Deliverables: <font color = 'green'>rnn.py</font>\n",
    "\n",
    "    - [2pts] \\_\\_init__ \n",
    "\n",
    "    - [8pts] forward \n",
    "        - [2pts] forward_embed\n",
    "        - [2pts] forward_rnn\n",
    "        - [2pts] forward_concat\n",
    "        - [2pts] forward\n",
    "- **3.2: Classifying Clickbait Dataset using RNN** [5pts] Deliverables: <font color = 'green'>rnn.py and best_rnn_model.pt</font>   \n",
    "\n",
    "### Q4: Classification with NN (3.75pts Bonus Extra Credit)\n",
    "- **(Submit to Bonus Extra Credit section in Gradescope)**\n",
    "- **4.1 Implementing NN** [1.25pts] Deliverables: <font color = 'green'>nn.py</font>\n",
    "\n",
    "    - [1.25pts] \\_\\_init__\n",
    "\n",
    "- **4.4: Classifying Web of Science Dataset using NN** [2.5pts] Deliverables: <font color = 'green'>nn.py and best_nn_model.pt</font> \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbdfe59",
   "metadata": {
    "id": "f462ddb9"
   },
   "source": [
    "# Setup\n",
    "**Please checkout the environment_setup.md file to create the environment for this homework.** This notebook is tested under the package versions noted in the Library Imports cell output below, and the corresponding packages can be downloaded from [miniconda](https://docs.conda.io/en/latest/miniconda.html). You may also want to get yourself familiar with several packages:\n",
    "\n",
    "- [jupyter notebook](https://jupyter-notebook.readthedocs.io/en/stable/)\n",
    "- [numpy](https://docs.scipy.org/doc/numpy-1.15.1/user/quickstart.html)\n",
    "- [sklearn](https://matplotlib.org/users/pyplot_tutorial.html)\n",
    "- [pytorch](https://pytorch.org/)\n",
    "\n",
    "In the .py files please implement the functions that have `raise NotImplementedError`, and after you finish the coding, please delete or comment out `raise NotImplementedError`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c5e21",
   "metadata": {
    "id": "f056b4ff"
   },
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afb15f88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "73b47510",
    "outputId": "28d7ed83-92ab-4951-de7e-79679cc41ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Version information\n",
      "python: 3.7.16 (default, Jan 17 2023, 09:28:58) \n",
      "[Clang 14.0.6 ]\n",
      "pandas: 1.3.5\n",
      "numpy: 1.21.5\n",
      "scipy: 1.7.3\n",
      "sns: 0.12.2\n",
      "gensim: 3.8.0\n",
      "torchtext: 0.14.1\n",
      "sklearn: 1.0.2\n",
      "torch: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "#Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sys, re, pickle, random\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "import gensim             \n",
    "import torchtext\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "torch.manual_seed(10)\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "print('Version information')\n",
    "\n",
    "print('python: {}'.format(sys.version))\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "print('scipy: {}'.format(sp.__version__))\n",
    "print('sns: {}'.format(sns.__version__))\n",
    "print('gensim: {}'.format(gensim.__version__))        \n",
    "print('torchtext: {}'.format(torchtext.__version__))\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "print('torch: {}'.format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c799c2",
   "metadata": {
    "id": "eff26cb3"
   },
   "source": [
    "# Load Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1752be",
   "metadata": {
    "id": "837cc1e5"
   },
   "source": [
    "We start by loading both data sets already split into an 80/20 train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "efd9b985",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "e2b97025",
    "outputId": "391ea7e2-f53d-40d4-cd91-d7989f239c7e"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# Separate dataframes into train and test lists\n",
    "x_train, y_train = list(df_train['headline']), list(df_train['label'])\n",
    "x_test, y_test = list(df_test['headline']), list(df_test['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100ab98e",
   "metadata": {
    "id": "15f2a21c"
   },
   "source": [
    "Below is the number of headlines in the train and test set as well as a sample of the article headlines and its binary label, where 0 is considered not clickbait and 1 is clickbait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "459229bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "11e3ebf5",
    "outputId": "97c351fe-624d-4b6c-b8e2-1cf03ad30dd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Headlines: 19200\n",
      "Number of Test Headlines: 4800\n",
      "\n",
      "\n",
      "Sample Label and Headlines:\n",
      "1: 27 Breathtaking Alternatives To A Traditional Wedding Bouquet <br>\n",
      "\n",
      "1: 22 Pictures People Who Aren't Grad Students Will <strong>Never</strong> Understand\n",
      "\n",
      "0: PepsiCo Profit Falls 43 Percent\n",
      "\n",
      "0: Website of Bill O'Reilly, FOX News commentator, hacked in retribution\n",
      "\n",
      "1: The Green Toy Soldiers From Your Childhood Now Come In Baller Yoga Poses A\n",
      "\n",
      "\n",
      "Output of Sample Headlines without Print Statement:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['27 Breathtaking Alternatives To A Traditional Wedding Bouquet <br>\\n',\n",
       " \"22 Pictures People Who Aren't Grad Students Will <strong>Never</strong> Understand\\n\",\n",
       " 'PepsiCo Profit Falls 43 Percent\\n',\n",
       " \"Website of Bill O'Reilly, FOX News commentator, hacked in retribution\\n\",\n",
       " 'The Green Toy Soldiers From Your Childhood Now Come In Baller Yoga Poses A\\n']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "print(f'Number of Train Headlines: {len(x_train)}')\n",
    "print(f'Number of Test Headlines: {len(x_test)}')\n",
    "\n",
    "print('\\n\\nSample Label and Headlines:')\n",
    "x = 105\n",
    "for label, line in zip(y_train[x:x+5], x_train[x:x+5]):\n",
    "    print(f'{label}: {line}')\n",
    "    \n",
    "print('\\nOutput of Sample Headlines without Print Statement:')\n",
    "x_train[x:x+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a62fabf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "20a8debc",
    "outputId": "2d934897-8f6f-49bb-a85c-d627017dd8b0"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "df_train_wos = pd.read_csv('./data/train_wos.csv')\n",
    "df_test_wos = pd.read_csv('./data/test_wos.csv')\n",
    "\n",
    "# Separate dataframes into train and test lists\n",
    "x_train_wos, y_train_wos = list(df_train_wos['article']), list(df_train_wos['label'])\n",
    "x_test_wos, y_test_wos = list(df_test_wos['article']), list(df_test_wos['label'])\n",
    "\n",
    "# Numerical label to domain mapping\n",
    "wos_label = {0:'CS', 1:'ECE', 2:'Civil', 3:'Medical'}\n",
    "# Numerical label to Numerical mapping\n",
    "label_mapping = {0:0, 1:1, 4:2, 5:3}\n",
    "\n",
    "for i, label in enumerate(y_train_wos):\n",
    "    y_train_wos[i] = label_mapping[label]\n",
    "for i, label in enumerate(y_test_wos):\n",
    "    y_test_wos[i] = label_mapping[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe87a32a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "d24ac5b6",
    "outputId": "f5df643b-a8d5-41de-cba7-eede9bbaa59c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Articles: 1600\n",
      "Number of Test Articles: 400\n",
      "\n",
      "Label Key: {0: 'CS', 1: 'ECE', 2: 'Civil', 3: 'Medical'}\n",
      "\n",
      "Sample Label and Articles:\n",
      "\n",
      "0 - CS: An efficient procedure for calculating the electromagnetic fields in multilayered cylindrical structures is reported in this paper. Using symbolic computation, spectral Green's functions, suitable for numerical implementations are determined in compact and closed forms. Applications are presented for structures with two dielectric layers.\n",
      "\n",
      "1 - ECE: A multifunctional platform based on the microhotplate was developed for applications including a Pirani vacuum gauge, temperature, and gas sensor. It consisted of a tungsten microhotplate and an on-chip operational amplifier. The platform was fabricated in a standard complementary metal oxide semiconductor (CMOS) process. A tungsten plug in standard CMOS process was specially designed as the serpentine resistor for the microhotplate, acting as both heater and thermister. With the sacrificial layer technology, the microhotplate was suspended over the silicon substrate with a 340 nm gap. The on-chip operational amplifier provided a bias current for the microhotplate. This platform has been used to develop different kinds of sensors. The first one was a Pirani vacuum gauge ranging from 10(-1) to 10(5) Pa. The second one was a temperature sensor ranging from -20 to 70 degrees C. The third one was a thermal-conductivity gas sensor, which could distinguish gases with different thermal conductivities in constant gas pressure and environment temperature. In the fourth application, with extra fabrication processes including the deposition of gas-sensitive film, the platform was used as a metal-oxide gas sensor for the detection of gas concentration.\n",
      "\n",
      "2 - Civil: Artificial neural networks have been effectively used in various civil engineering fields, including construction management and labour productivity. In this study, the performance of the feed forward neural network (FFNN) was compared with radial basis neural network (RBNN) in modelling the productivity of masonry crews. A variety of input factors were incorporated and analysed. Mean absolute percentage error (MAPE) and correlation coefficient (R) were used to evaluate model performance. Research results indicated that the neural computing techniques could be successfully employed in modelling crew productivity. It was also found that successful models could be developed with different combinations of input factors, and several of the models which excluded one or more input factors turned out to be better than the baseline models. Based on the MAPE values obtained for the models, the RBNN technique was found to be better than the FFNN technique, although both slightly overestimated the masons' productivity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "print(f'Number of Train Articles: {len(x_train_wos)}')\n",
    "print(f'Number of Test Articles: {len(x_test_wos)}')\n",
    "\n",
    "print('\\nLabel Key:', wos_label)\n",
    "\n",
    "print('\\nSample Label and Articles:\\n')\n",
    "x = 107\n",
    "for label, line in zip(y_train_wos[x:x+3], x_train_wos[x:x+3]):\n",
    "    print(f'{label} - {wos_label[label]}: {line}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d62fce",
   "metadata": {
    "id": "7M6Npz6qFN1q"
   },
   "source": [
    "## Q1: Word2Vec [45pts]\n",
    "\n",
    "Word2vec is a method to efficiently create word embeddings. More details on word2vec and the intuition behind it can be found here :  \n",
    "* [The Illustrated Word2vec by Jay Alammar](https://jalammar.github.io/illustrated-word2vec/)\n",
    "\n",
    "Word2vec is based on the idea that a wordâ€™s meaning is defined by its context. Context is represented as surrounding words. For the word2vec model, context is represented as N words before and N words after the current word. N is a hyperparameter. With larger N we can create better embeddings, but at the same time, such a model requires more computational resources. \n",
    "\n",
    "There are two word2vec architectures proposed in the paper:\n",
    "\n",
    "* CBOW (Continuous Bag-of-Words) â€” a model that predicts a current word based on its context words.\n",
    "* Skip-Gram â€” a model that predicts context words based on the current word.\n",
    "\n",
    "We will be running our Word2Vec models on a very small dataset as described below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96536423",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "mC1mB6pYqP4U",
    "outputId": "41393f89-e928-40c9-c875-e603e36affd9"
   },
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'he is a king',\n",
    "    'she is a queen',\n",
    "    'he is a man',\n",
    "    'she is a woman',\n",
    "    'warsaw is poland capital',\n",
    "    'berlin is germany capital',\n",
    "    'paris is france capital',   \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e54b75",
   "metadata": {
    "id": "-Np3UUmtFUjd"
   },
   "source": [
    "## 1.1: Implementing Continuous Bag-of-words From Scratch [26pts]\n",
    "In the **word2vec.py** file complete the following functions:\n",
    "  * <strong>tokenize</strong> (Word2Vec class)\n",
    "  * <strong>create_vocabulary</strong> (Word2Vec class)\n",
    "  * <strong>cbow_embeddings</strong> (Word2Vec class)\n",
    "  * <strong>\\_\\_init__</strong> (CBOW_Model class)\n",
    "  * <strong>forward</strong> (CBOW_Model class)\n",
    "\n",
    "A high level overview of the CBOW model can be described as :    \n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/1*ETcgajy5s0KNIfMgE5xOqg.png\" width=\"75%\" align=\"center\"></p>\n",
    "\n",
    "CBOW model takes several words, each goes through the same Embedding layer, and then word embedding vectors are averaged before going into the Linear layer.\n",
    "\n",
    "We will be implementing this model using the architecture described below :    \n",
    "\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/1*mLDM3PH12CjhaFoUm5QTow.png\" width=\"75%\" align=\"center\"></p>\n",
    "\n",
    "Here are the steps that needs to be followed for implementing CBOW model :    \n",
    "* Step-1: Create vocabulary\n",
    "  * Split each words into tokens.\n",
    "  * Assign a unique ID to each unique token.\n",
    "\n",
    "* Step-2: Create CBOW Embeddings\n",
    "  * Create CBOW embeddings by taking context as N past words and N future words.\n",
    "\n",
    "* Step-3: Implement CBOW Model\n",
    "  * Implement CBOW model as described in the architecture above.\n",
    "  \n",
    "<b>Hint:</b> Since we are using the cross entropy loss, there is no need to apply the softmax after the linear layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e349c0f",
   "metadata": {},
   "source": [
    "### 1.1.1: Local Tests for CBOW Functions [No Points]\n",
    "You may test your implementation of the CBOW functions contained in **word2vec.py** in the cell below. Feel free to comment out tests for functions that have not been completed yet. See [Using the Local Tests](#using_local_tests) for more details.\n",
    "\n",
    "ðŸ¦Š *Hint: Did you know that pytorch state dicts are dictionaries? You can load the basic_cbow_model.pt file into a variable to see the expected shapes of the layers and compare to your model's initalized layer shapes. See line 32 for an example on how to access the cbow model's state dict. Feel free to try this out for other models in this homework.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1d37c9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Tests for Word2Vec & CBOW Functions \n",
      "\n",
      "Your tokenize works as expected: True\n",
      "Your create_vocabulary works as expected: True\n",
      "Your cbow_embeddings works as expected: False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x2 and 300x9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xj/h6l08hhs3xg7js0z8rfj08qw0000gn/T/ipykernel_59458/4094145880.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbow_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbow_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbow_source\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     output_test = (torch.allclose(output, local_test.cbow_forward[i], rtol=0.0001, atol=0.0001) and \\\n\u001b[1;32m     42\u001b[0m                       output.shape == local_test.cbow_forward[i].shape)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_hw3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/ANLP/HW3/hw3_code/word2vec.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \"\"\"\n\u001b[1;32m    215\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_hw3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_hw3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x2 and 300x9)"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from word2vec import Word2Vec, CBOW_Model\n",
    "from local_tests.word2vec_test import Word2Vec_Test\n",
    "\n",
    "local_test = Word2Vec_Test()\n",
    "stu_w2v = Word2Vec()\n",
    "\n",
    "print('Local Tests for Word2Vec & CBOW Functions \\n')\n",
    "\n",
    "# Local test for tokenize\n",
    "output = stu_w2v.tokenize(local_test.corpus_data)\n",
    "tokens_test = (output == local_test.tokens)\n",
    "print('Your tokenize works as expected:', tokens_test)\n",
    "\n",
    "# Local test for create_vocabulary\n",
    "stu_w2v.create_vocabulary(local_test.tokens)\n",
    "create_vocab_test = ((stu_w2v.word2idx == local_test.word2idx) and (stu_w2v.idx2word == local_test.idx2word) and \\\n",
    "                     (stu_w2v.vocabulary_size == local_test.vocab_size))\n",
    "print('Your create_vocabulary works as expected:', create_vocab_test)\n",
    "\n",
    "# Local test for cbow_embeddings\n",
    "source, target = stu_w2v.cbow_embeddings(local_test.tokens)\n",
    "cbow_embed_test = ((source == local_test.cbow_source) and (target == local_test.cbow_target))\n",
    "print('Your cbow_embeddings works as expected:', cbow_embed_test)\n",
    "\n",
    "# Instantiate CBOW_Model and load weights for local tests\n",
    "torch.manual_seed(10)\n",
    "cbow_model = CBOW_Model(local_test.vocab_size)\n",
    "cbow_state_dict = cbow_model.state_dict()\n",
    "\n",
    "# If loading the state dict causes an error, then there may be an issue with your init implementation\n",
    "cbow_model.load_state_dict(torch.load('./local_tests/basic_cbow_model.pt'))\n",
    "\n",
    "# Local test for forward\n",
    "outputs = []\n",
    "for i in range(len(local_test.cbow_source)):\n",
    "    output = cbow_model(torch.from_numpy(np.array(local_test.cbow_source[i])))\n",
    "    output_test = (torch.allclose(output, local_test.cbow_forward[i], rtol=0.0001, atol=0.0001) and \\\n",
    "                      output.shape == local_test.cbow_forward[i].shape)\n",
    "    outputs.append(output_test)\n",
    "forward_test = np.all(outputs)\n",
    "print('Your forward works as expected:', forward_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed38c977",
   "metadata": {
    "id": "jd9OaAf9qZ5r"
   },
   "source": [
    "### 1.1.2: Fetching CBOW embeddings [No Points]\n",
    "Run the below cell to fetch CBOW embeddings using functions that you have already implemented in **1.1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c7190cb4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "6bd51ab7",
    "outputId": "2ecda65b-64cc-458b-9c1c-102cb0a9e7b1"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from word2vec import Word2Vec\n",
    "\n",
    "w2v = Word2Vec()\n",
    "tokens = w2v.tokenize(corpus)\n",
    "w2v.create_vocabulary(tokens)\n",
    "source, target = w2v.cbow_embeddings(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309593a2",
   "metadata": {
    "id": "3t3BiUU1rMM6"
   },
   "source": [
    "### 1.1.3: Training CBOW model [No Points]\n",
    "Run the below cell to train CBOW model using functions that you have already implemented in **1.1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ae488380",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "1fCSFxldedmf",
    "outputId": "6dc04ce3-941e-409e-8a62-e758b2ad4f3e"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x3 and 300x15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xj/h6l08hhs3xg7js0z8rfj08qw0000gn/T/ipykernel_59458/1844942774.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_hw3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/ANLP/HW3/hw3_code/word2vec.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Shape: (batch_size, window_size * 2, EMBED_DIMENSION)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Average the embeddings along the window dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_hw3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp_hw3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x3 and 300x15)"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from word2vec import CBOW_Model\n",
    "\n",
    "N_EPOCHS = 300\n",
    "model = CBOW_Model(w2v.vocabulary_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    shuffled_i = list(range(0,len(target)))\n",
    "    random.shuffle(shuffled_i)\n",
    "    for i in shuffled_i:\n",
    "        x = torch.from_numpy(np.asarray(source[i])).long().to(device)\n",
    "        y = torch.from_numpy(np.asarray(target[i])).long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 20 == 0:    \n",
    "        print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8005c3",
   "metadata": {
    "id": "GvdTvbADsOgr"
   },
   "source": [
    "### 1.1.4: Visualizing CBOW embeddings [No Points]\n",
    "Run the below cells to visualize CBOW embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9b15b86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "pgmVkIigg1xr",
    "outputId": "94f2ec1e-dfe6-4c7d-ab93-adbd4785d308"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# embedding from first model layer\n",
    "embeddings = list(model.parameters())[0]\n",
    "embeddings = embeddings.cpu().detach().numpy()\n",
    "\n",
    "# normalization\n",
    "norms = (embeddings ** 2).sum(axis=1) ** (1 / 2)\n",
    "norms = np.reshape(norms, (len(norms), 1))\n",
    "embeddings_norm = embeddings / norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3446d4c5",
   "metadata": {},
   "source": [
    "Here, we use truncated SVD to project the learned word2vec embedding to 2D space for visualization. Feel free to tune the learning rate in the training part for different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7181380e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "PYcXX6AIpcun",
    "outputId": "6a76217b-527b-410c-ae23-e81eccd32115"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import decomposition\n",
    "\n",
    "w2v.word2idx[''] = 0\n",
    "svd = decomposition.TruncatedSVD(n_components=2)\n",
    "W2_dec = svd.fit_transform(embeddings)\n",
    "\n",
    "x = W2_dec[:,0]\n",
    "y = W2_dec[:,1]\n",
    "plot = sns.scatterplot(x=x, y=y)\n",
    "\n",
    "for i in range(0,W2_dec.shape[0]):\n",
    "     plot.text(x[i], y[i]+2e-2, list(w2v.word2idx)[i], horizontalalignment='center', size='small', color='black', weight='semibold');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803a54da",
   "metadata": {},
   "source": [
    "Here, we will look into the learned property of the word2vec embedding. Warsaw is the capital of Poland and we now calculate the difference between embeddings of \"warsaw\" and \"poland\". After that, we add the difference to the embedding of \"paris\". We then rank the dot product of the computed embedding vs all the embeddings. Notice that the larger this value, the more similar two embeddings are. Feel free to play with different word pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79d90603",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "3V4LYCq5mVB1",
    "outputId": "c652ce3a-0ca3-49f6-ec29-d1b22c0fdb6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris: 0.604\n",
      "poland: 0.539\n",
      "germany: 0.052\n",
      "man: 0.051\n",
      "a: 0.028\n"
     ]
    }
   ],
   "source": [
    "emb1 = embeddings[w2v.word2idx[\"poland\"]]\n",
    "emb2 = embeddings[w2v.word2idx[\"warsaw\"]]\n",
    "emb3 = embeddings[w2v.word2idx[\"paris\"]]\n",
    "\n",
    "emb4 = emb1 - emb2 + emb3\n",
    "emb4_norm = (emb4 ** 2).sum() ** (1 / 2)\n",
    "emb4 = emb4 / emb4_norm\n",
    "\n",
    "emb4 = np.reshape(emb4, (len(emb4), 1))\n",
    "dists = np.matmul(embeddings_norm, emb4).flatten()\n",
    "\n",
    "top5 = np.argsort(-dists)[:5]\n",
    "\n",
    "for word_id in top5:\n",
    "    print(\"{}: {:.3f}\".format(w2v.idx2word[word_id], dists[word_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4df03",
   "metadata": {
    "id": "4TLUiFFR7wlL"
   },
   "source": [
    "## 1.2: Implementing Skip-Gram From Scratch [19pts]\n",
    "In the **word2vec.py** file complete the following functions:\n",
    "  * <strong>skipgram_embeddings</strong> (Word2Vec class)\n",
    "  * <strong>\\_\\_init__</strong> (SkipGram_Model class)\n",
    "  * <strong>forward</strong> (SkipGram_Model class)\n",
    "\n",
    "A high level overview of the SkipGram model can be described as :    \n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/720/1*SVs6xTpD7AYviP24UTOYUA.png\" width=\"75%\" align=\"center\"></p>\n",
    "\n",
    "The Skip-Gram model takes a single word as compared to CBOW model.\n",
    "\n",
    "We will be implementing this model using the architecture described below :    \n",
    "\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/720/1*eHh1_t8Wms_hqDNBLuAnFg.png\" width=\"75%\" align=\"center\"></p>\n",
    "\n",
    "Here are the steps that needs to be followed for implementing SkipGram model :    \n",
    "* Step-1: Create vocabulary\n",
    "  * Split each words into tokens.\n",
    "  * Assign a unique ID to each unique token.\n",
    "\n",
    "* Step-2: Create SkipGram Embeddings\n",
    "  * Create SkipGram embeddings by taking context as middle word.\n",
    "\n",
    "* Step-3: Implement SkipGram Model\n",
    "  * Implement SkipGram model as described in the architecture above. Output SkipGram embeddings for N past words and N future words.\n",
    "\n",
    "**Hint:** Since we are using the cross entropy loss, there is no need to apply the softmax after the linear layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083dd7b4",
   "metadata": {},
   "source": [
    "### 1.2.1: Local Tests for SkipGram Functions [No Points]\n",
    "You may test your implementation of the SkipGram functions contained in **word2vec.py** in the cell below. Feel free to comment out tests for functions that have not been completed yet. See [Using the Local Tests](#using_local_tests) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3647080d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Tests for Skipgram Functions \n",
      "\n",
      "Your skipgram_embeddings works as expected: False\n",
      "Your forward works as expected: True\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from word2vec import Word2Vec, SkipGram_Model\n",
    "from local_tests.word2vec_test import Word2Vec_Test\n",
    "\n",
    "local_test = Word2Vec_Test()\n",
    "stu_w2v = Word2Vec()\n",
    "stu_w2v.create_vocabulary(local_test.tokens)\n",
    "\n",
    "print('Local Tests for Skipgram Functions \\n')\n",
    "\n",
    "# Local test for skipgram_embeddings\n",
    "source, target = stu_w2v.skipgram_embeddings(local_test.tokens)\n",
    "skipgram_embed_test = ((source == local_test.sg_source) and (target == local_test.sg_target))\n",
    "print('Your skipgram_embeddings works as expected:', skipgram_embed_test)\n",
    "\n",
    "# Instantiate SkipGram_Model and load weights for local tests\n",
    "torch.manual_seed(10)\n",
    "sg_model = SkipGram_Model(local_test.vocab_size)\n",
    "# If loading the state dict causes an error, then there may be an issue with your init implementation\n",
    "sg_model.load_state_dict(torch.load('./local_tests/basic_sg_model.pt'))\n",
    "\n",
    "# Local test for forward\n",
    "output = sg_model(torch.from_numpy(np.array(local_test.sg_source[:12])).squeeze())\n",
    "forward_test = (torch.allclose(output, local_test.sg_forward, rtol=0.0001, atol=0.0001) and \\\n",
    "                      output.shape == local_test.sg_forward.shape)\n",
    "print('Your forward works as expected:', forward_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a35f4e5",
   "metadata": {
    "id": "IVCLHrC788LU"
   },
   "source": [
    "### 1.2.2: Fetching SkipGram embeddings [No Points]\n",
    "Run the below cell to fetch **SkipGram** embeddings using functions that you have already implemented in 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d1458760",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "ecu9TMvO83p9",
    "outputId": "f658bea1-dbdc-4867-d1fd-9b0bf25cc2e7"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from word2vec import Word2Vec\n",
    "\n",
    "w2v = Word2Vec()\n",
    "tokens = w2v.tokenize(corpus)\n",
    "w2v.create_vocabulary(tokens)\n",
    "source, target = w2v.skipgram_embeddings(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14474b0",
   "metadata": {
    "id": "4lU_G6iB9N9d"
   },
   "source": [
    "### 1.2.3: Training SkipGram model [No Points]\n",
    "Run the below cell to train SkipGram model using functions that you have already implemented in **1.2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e36a36e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "JGRhDekI83si",
    "outputId": "c7fec093-54d0-4b8a-95b0-21b5030e6fa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 0: 187.859772\n",
      "loss on epoch 20: 125.341278\n",
      "loss on epoch 40: 119.413605\n",
      "loss on epoch 60: 116.676491\n",
      "loss on epoch 80: 116.056961\n",
      "loss on epoch 100: 114.893707\n",
      "loss on epoch 120: 115.755783\n",
      "loss on epoch 140: 115.431396\n",
      "loss on epoch 160: 114.760101\n",
      "loss on epoch 180: 114.308029\n",
      "loss on epoch 200: 114.472580\n",
      "loss on epoch 220: 113.960655\n",
      "loss on epoch 240: 113.542458\n",
      "loss on epoch 260: 114.482498\n",
      "loss on epoch 280: 112.369637\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from word2vec import SkipGram_Model\n",
    "\n",
    "N_EPOCHS = 300\n",
    "model = SkipGram_Model(w2v.vocabulary_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    shuffled_i = list(range(0,len(target)))\n",
    "    random.shuffle(shuffled_i)\n",
    "    for i in shuffled_i:\n",
    "        x = torch.from_numpy(np.asarray(source[i])).long().to(device)\n",
    "        y = torch.from_numpy(np.asarray(target[i])).long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 20 == 0:    \n",
    "        print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e0867a",
   "metadata": {
    "id": "HOthB5MD9ruv"
   },
   "source": [
    "### 1.2.4: Visualizing SkipGram embeddings [No Points]\n",
    "Run the below cells to visualize SkipGram embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "12530833",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "MW64QQ4n83vK",
    "outputId": "acb32f8c-6dde-4277-c519-fa9a1977c548"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# embedding from first model layer\n",
    "embeddings = list(model.parameters())[0]\n",
    "embeddings = embeddings.cpu().detach().numpy()\n",
    "\n",
    "# normalization\n",
    "norms = (embeddings ** 2).sum(axis=1) ** (1 / 2)\n",
    "norms = np.reshape(norms, (len(norms), 1))\n",
    "embeddings_norm = embeddings / norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eff41cd",
   "metadata": {},
   "source": [
    "Here, we use truncated SVD to project the learned word2vec embedding to 2D space for visualization. Feel free to tune the learning rate in the training part for different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "33dc3ff5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "iLhTgwE183xt",
    "outputId": "832755ed-5da8-47b4-eb4a-41d15f938d65"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from sklearn import decomposition\n",
    "\n",
    "w2v.word2idx[''] = 0\n",
    "svd = decomposition.TruncatedSVD(n_components=2)\n",
    "W2_dec = svd.fit_transform(embeddings)\n",
    "\n",
    "x = W2_dec[:,0]\n",
    "y = W2_dec[:,1]\n",
    "plot = sns.scatterplot(x=x, y=y)\n",
    "\n",
    "for i in range(0,W2_dec.shape[0]):\n",
    "     plot.text(x[i], y[i]+2e-2, list(w2v.word2idx)[i], horizontalalignment='center', size='small', color='black', weight='semibold');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52f24e",
   "metadata": {},
   "source": [
    "Here, we will look into the learned property of the word2vec embedding. Warsaw is the capital of Poland and we now calculate the difference between embeddings of \"warsaw\" and \"poland\". After that, we add the difference to the embedding of \"paris\". We then rank the dot product of the computed embedding vs all the embeddings. Notice that the larger this value, the more similar two embeddings are. Feel free to play with different word pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ea212b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "6Opu7Awy979w",
    "outputId": "058539e5-171d-4c34-b086-5a283fc82684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poland: 0.684\n",
      "paris: 0.512\n",
      "germany: 0.401\n",
      "france: 0.368\n",
      "he: 0.155\n"
     ]
    }
   ],
   "source": [
    "emb1 = embeddings[w2v.word2idx[\"poland\"]]\n",
    "emb2 = embeddings[w2v.word2idx[\"warsaw\"]]\n",
    "emb3 = embeddings[w2v.word2idx[\"paris\"]]\n",
    "\n",
    "emb4 = emb1 - emb2 + emb3\n",
    "emb4_norm = (emb4 ** 2).sum() ** (1 / 2)\n",
    "emb4 = emb4 / emb4_norm\n",
    "\n",
    "emb4 = np.reshape(emb4, (len(emb4), 1))\n",
    "dists = np.matmul(embeddings_norm, emb4).flatten()\n",
    "\n",
    "top5 = np.argsort(-dists)[:5]\n",
    "\n",
    "for word_id in top5:\n",
    "    print(\"{}: {:.3f}\".format(w2v.idx2word[word_id], dists[word_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad08f83d",
   "metadata": {
    "id": "DqJwpMAYUg4A"
   },
   "source": [
    "Ideally with large amount of data, we should have got france as the most nearest word. But depending on the implementation and amount of data, it can vary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64882a2d",
   "metadata": {
    "id": "dRvybL9rYxcQ"
   },
   "source": [
    "## Q2: Classification with CNN [15pts]\n",
    "\n",
    "Convolutional layers are used to find patterns by sliding a small kernel window over the input. In computer vision applications, the kernel window slides through and gets multiplied by small regions in an image. In the context of NLP, the kernel slides through and gets multiplied by the embedding vectors of a few words as specified by window size. For looking at sequences of word embeddings, the window has to look at multiple word embeddings in a sequence. The kernel will be rectangular with size window_size x embedding_size. For example, if window size is 3 then the kernel size will be 3 x 500. This essentially represents n-grams in the model. The kernel weights (filter) are multiplied to word embeddings in pairs and summed up to get output values. As the network is being learned, these kernel weights are also being learned.\n",
    "\n",
    "We will be implementing a convolutional neural network with a pre-trained word2vec model for classification similar to the CNN-rand baseline described by [Kim (2014)](https://aclanthology.org/D14-1181.pdf). Although our model differs from the paper, it may still be helpful to review the model section of the paper to get a general overview of the architecture. We will use a pre-trained word2vec model for feasibility of finding the appropriate embeddings. The architecture of our model looks like:\n",
    "\n",
    "<p align=\"center\"><img src=\"https://cezannec.github.io/assets/cnn_text/complete_text_classification_CNN.png\" width=\"75%\" align=\"center\"></p>\n",
    "\n",
    "We will be using an embedding layer loaded with a word2vec model, followed by convolution layers, and then a linear layer.\n",
    "\n",
    "We will be using the Clickbait and Web of Science dataset for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9365467c",
   "metadata": {
    "id": "5hBTTf_0bDWd"
   },
   "source": [
    "## 2.1: Implementing CNN Classifier [10pts]\n",
    "In the **cnn.py** file complete the following functions:\n",
    "  * <strong>\\_\\_init__</strong>\n",
    "  * <strong>forward_embed</strong>\n",
    "  * <strong>forward_convs</strong>\n",
    "  * <strong>forward</strong>\n",
    "  \n",
    "We have included local tests in 2.1.3 for you to test your implementation of the CNN functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd89ef",
   "metadata": {
    "id": "BlQWYkt6bjPM"
   },
   "source": [
    "### 2.1.1: Pre-Processing Data [No Points]\n",
    "\n",
    "Run the below cell to preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ea19c2a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "QtXq7iy3bwrs",
    "outputId": "e4849779-987a-4a07-d1bb-c4cb867814bc"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def preprocess(data):\n",
    "    preprocessed_data = []\n",
    "    for text in data:\n",
    "        tokens = simple_preprocess(text, deacc=True)\n",
    "        preprocessed_data.append(tokens)\n",
    "    return preprocessed_data\n",
    "\n",
    "preprocessed_x_train = preprocess(x_train)\n",
    "preprocessed_x_train_wos = preprocess(x_train_wos)\n",
    "\n",
    "preprocessed_x_test = preprocess(x_test)\n",
    "preprocessed_x_test_wos = preprocess(x_test_wos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4dcf1840",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "_M0alpCXcN3N",
    "outputId": "6ffd3641-ff5e-4366-958d-f18399a31bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for running: \n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# Use cuda if present\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running: \")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f84828",
   "metadata": {
    "id": "vOr_wpjNdGnj"
   },
   "source": [
    "### 2.1.2: Utility functions for training Word2Vec Model [No Points]\n",
    "\n",
    "Run the below cells for making word2vec model, vectors and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8cd10d38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "3gjLdwNOdOYd",
    "outputId": "2315178e-7fd3-42bd-c555-8af5915f7976"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "size = 500\n",
    "window = 3\n",
    "min_count = 1\n",
    "workers = 3\n",
    "sg = 1\n",
    "\n",
    "# Function to train word2vec model\n",
    "def make_word2vec_model(data, padding=True, sg=1, min_count=1, size=500, workers=3, window=3):\n",
    "    data.append(['pad'])\n",
    "    w2v_model = Word2Vec(data, min_count = min_count, size = size, workers = workers, window = window, sg = sg)\n",
    "    return w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b0c69923",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "DTUjqQnjdOUz",
    "outputId": "11051581-803c-477e-9788-af3d12a9e201"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "def make_word2vec_vector(sentence):\n",
    "    padded_X = [padding_idx for i in range(max_sen_len)]\n",
    "    i = 0\n",
    "    for word in sentence:\n",
    "        if word not in w2vmodel.wv.vocab:\n",
    "            padded_X[i] = 0\n",
    "        else:\n",
    "            padded_X[i] = w2vmodel.wv.vocab[word].index\n",
    "        i += 1\n",
    "    return torch.tensor(padded_X, dtype=torch.long, device=device).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c27ba2a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "PrOTzz5gddgj",
    "outputId": "70681d17-e12c-44bd-8be2-fd7be0c7b8c9"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "def make_target(label):\n",
    "    return torch.tensor([label], dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d136a5",
   "metadata": {},
   "source": [
    "### 2.1.3: Local Tests for CNN Functions [No Points]\n",
    "You may test your implementation of the functions contained in **cnn.py** in the cell below. Feel free to comment out tests for functions that have not been completed yet. See [Using the Local Tests](#using_local_tests) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7ce03e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Tests for CNN Implementation \n",
      "\n",
      "Your forward_embed works as expected: True\n",
      "Your forward_convs works as expected: False\n",
      "Your forward works as expected: True\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from cnn import CNN\n",
    "from local_tests.cnn_test import CNN_Test\n",
    "torch.manual_seed(10)\n",
    "local_test = CNN_Test()\n",
    "\n",
    "# creating the local test dataset for CNN\n",
    "local_test_dataset = local_test.input_sequences\n",
    "preprocessed_x_local_test = preprocess(local_test_dataset)\n",
    "\n",
    "w2vmodel_test = make_word2vec_model(preprocessed_x_local_test, padding=True, sg=sg, min_count=min_count, size=size, workers=workers, window=window)\n",
    "cnn_model = CNN(w2vmodel_test, num_classes=2, window_sizes=(1,2,3,5))\n",
    "cnn_model.load_state_dict(torch.load('./local_tests/basic_cnn_model.pt'))    # upload default weights. If this errors out, make sure you have initialized the layers correctly.\n",
    "cnn_model.eval()\n",
    "\n",
    "max_sen_len = max(map(len, preprocessed_x_local_test))\n",
    "padding_idx = w2vmodel_test.wv.vocab['pad'].index\n",
    "def make_word2vec_vector_test(sentence):\n",
    "    padded_X = [padding_idx for i in range(max_sen_len)]\n",
    "    i = 0\n",
    "    for word in sentence:\n",
    "        if word not in w2vmodel_test.wv.vocab:\n",
    "            padded_X[i] = 0\n",
    "        else:\n",
    "            padded_X[i] = w2vmodel_test.wv.vocab[word].index\n",
    "        i += 1\n",
    "    return torch.tensor(padded_X, dtype=torch.long, device=device).view(1, -1)\n",
    "x_local_test = make_word2vec_vector_test(preprocessed_x_local_test[0])\n",
    "\n",
    "print('Local Tests for CNN Implementation \\n')\n",
    "\n",
    "# Local test for forward_embed\n",
    "embeddings = cnn_model.forward_embed(x_local_test)\n",
    "forward_embed_test = (embeddings.shape == local_test.embeddings.shape) and (torch.allclose(embeddings, local_test.embeddings, rtol=0.0001, atol=0.0001))\n",
    "print('Your forward_embed works as expected:', forward_embed_test)\n",
    "\n",
    "# Local test for forward_rnn\n",
    "convs_output = cnn_model.forward_convs(local_test.embeddings)\n",
    "forward_convs_test = (convs_output.shape == local_test.convs_output.shape) and (torch.allclose(convs_output, local_test.convs_output, rtol=0.0001, atol=0.0001))\n",
    "print('Your forward_convs works as expected:', forward_convs_test)\n",
    "\n",
    "# Local test for forward\n",
    "x_local_test = torch.concat((x_local_test, make_word2vec_vector_test(preprocessed_x_local_test[1]), \\\n",
    "                             make_word2vec_vector_test(preprocessed_x_local_test[2])), axis=0)\n",
    "local_test.output = torch.tensor([[-0.1408,  0.0695], [-0.1383,  0.0646], [-0.2037,  0.1318]])\n",
    "cnn_forward_output = cnn_model.forward(x_local_test)\n",
    "forward_test = (cnn_forward_output.shape == local_test.output.shape) and (torch.allclose(cnn_forward_output, local_test.output, rtol=0.0001, atol=0.0001))\n",
    "print('Your forward works as expected:', forward_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6f0d97",
   "metadata": {
    "id": "fXuJ6ouncC8Z"
   },
   "source": [
    "## 2.2: Classifying Clickbait Dataset using CNN [No Points]\n",
    "\n",
    "Run the below cell to classify the Clickbait train and test dataset using the CNN functions that you have already implemented in 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bbd9501c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "lurnaUoUXCcU",
    "outputId": "dece0006-ceab-4123-cb16-7e728f2e6f3c"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# Train Word2vec model\n",
    "w2vmodel = make_word2vec_model(preprocessed_x_train, padding=True, sg=sg, min_count=min_count, size=size, workers=workers, window=window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803c25f",
   "metadata": {},
   "source": [
    "Because CNN requires the input data to be of the same length. We use the embedding of the \"pad\" word as the padding vector. Notice that this choice is just a convention and other tokens could also work for this purpose. In more complex language model, there will be a dedicated '\\<pad\\>' token for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "857fcd53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "MnRN7kn7XCe6",
    "outputId": "39df6412-550c-4e4c-c892-3473877470da"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "max_sen_len = max(map(len, preprocessed_x_train))\n",
    "padding_idx = w2vmodel.wv.vocab['pad'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f97009ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "zIdO6zAsUMGV",
    "outputId": "d7cce669-26ac-45cc-e11c-827cfd122925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 0: 3229.605417\n",
      "loss on epoch 1: 2923.921273\n",
      "loss on epoch 2: 2795.434628\n",
      "loss on epoch 3: 2714.403430\n",
      "loss on epoch 4: 2641.113149\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from cnn import CNN\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "model = CNN(w2vmodel, num_classes=NUM_CLASSES)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "N_EPOCHS = 5\n",
    "\n",
    "model.train()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    shuffled_i = list(range(0,len(y_train)))\n",
    "    random.shuffle(shuffled_i)\n",
    "\n",
    "    for index in range(len(shuffled_i)):\n",
    "        model.zero_grad()\n",
    "        bow_vec = make_word2vec_vector(preprocessed_x_train[index])\n",
    "        outputs = model(bow_vec)\n",
    "        y = make_target(y_train[index])\n",
    "\n",
    "        loss = criterion(outputs, y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a4a2ef98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "aOiTWeR6VDXk",
    "outputId": "b02e1d0d-5194-4b47-faec-cdba1a3b330f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on Clickbait Dataset using CNN : 0.940\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "cnn_predictions = []\n",
    "original_lables_cnn = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index in range(len(y_test)):\n",
    "        bow_vec = make_word2vec_vector(preprocessed_x_test[index])\n",
    "        probs = model(bow_vec)\n",
    "        _, predicted = torch.max(probs.data, 1)\n",
    "        cnn_predictions.append(predicted.cpu().numpy()[0])\n",
    "        t = make_target(y_test[index]).cpu().numpy()[0]\n",
    "        original_lables_cnn.append(make_target(y_test[index]).cpu().numpy()[0])\n",
    "\n",
    "print(\"Test Accuracy on Clickbait Dataset using CNN : {:.3f}\".format(accuracy_score(original_lables_cnn, cnn_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acea61ff",
   "metadata": {
    "id": "lRXO38UrmQ18"
   },
   "source": [
    "## 2.3: Classifying Web of Science Dataset using CNN [5pts]\n",
    "\n",
    "Run the below cell to classify the WoS train and test dataset using the CNN functions that you have already implemented in 2.\n",
    "\n",
    "**You must reach an accuracy of >= 50% to receive credit for this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "525cdaee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "XUyZvrX3mWXj",
    "outputId": "90050d4c-c393-483d-c76d-d7cc475e3ce7"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# Train Word2vec model\n",
    "w2vmodel = make_word2vec_model(preprocessed_x_train_wos, padding=True, sg=sg, min_count=min_count, size=size, workers=workers, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "72f6f795",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "dP07m73fRM44",
    "outputId": "28f17390-69d5-4178-f8ec-9a51ae9dbaa6"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "load_pt = False\n",
    "max_sen_len = max(map(len, preprocessed_x_train_wos))\n",
    "padding_idx = w2vmodel.wv.vocab['pad'].index\n",
    "\n",
    "# Uncomment for use if there is a discrepancy in testing accuracy between notebook and gradescope\n",
    "# load_pt = True\n",
    "# train_dataset = torch.load('./data/cnn_train_dataset_wos.pt')\n",
    "# test_dataset = torch.load('./data/cnn_test_dataset_wos.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7babbff9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "HZPVaPsvmoDR",
    "outputId": "21294fa2-48a5-455e-c7fa-fd8d5d9c602f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 0: 1685.428897\n",
      "loss on epoch 5: 1001.306720\n",
      "loss on epoch 10: 833.434000\n",
      "loss on epoch 15: 723.995158\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from cnn import CNN\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "model = CNN(w2vmodel, num_classes=NUM_CLASSES)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "N_EPOCHS = 20\n",
    "\n",
    "model.train()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    shuffled_i = list(range(0,len(y_train_wos)))\n",
    "    random.shuffle(shuffled_i)\n",
    "\n",
    "    for index in range(len(shuffled_i)):\n",
    "        model.zero_grad()\n",
    "        bow_vec = make_word2vec_vector(preprocessed_x_train_wos[index]) if not load_pt else train_dataset[index][0].unsqueeze(0)\n",
    "        outputs = model(bow_vec)\n",
    "        y = make_target(y_train_wos[index] if not load_pt else train_dataset[index][1])\n",
    "        \n",
    "        loss = criterion(outputs, y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    if epoch % 5 == 0:    \n",
    "        print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4b0e4d3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "E3bSg3HCYnIS",
    "outputId": "e47cc8c4-3846-46bc-f7b2-7120947e8263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on WoS Dataset using CNN : 0.585\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "cnn_predictions = []\n",
    "original_lables_cnn = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index in range(len(y_test_wos)):\n",
    "        bow_vec = make_word2vec_vector(preprocessed_x_test_wos[index]) if not load_pt else test_dataset[index][0].unsqueeze(0)\n",
    "        probs = model(bow_vec)\n",
    "        _, predicted = torch.max(probs.data, 1)\n",
    "        cnn_predictions.append(predicted.cpu().numpy()[0])\n",
    "        t = make_target(y_test_wos[index] if not load_pt else train_dataset[index][1]).cpu().numpy()[0] \n",
    "        original_lables_cnn.append(t)\n",
    "\n",
    "print(\"Test Accuracy on WoS Dataset using CNN : {:.3f}\".format(accuracy_score(original_lables_cnn, cnn_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c01b7",
   "metadata": {
    "id": "px4Og3agxxkY"
   },
   "source": [
    "### ðŸ¥ <font color='darkred'>Submit these files to Gradescope</font><a id='find_chicken'></a>\n",
    "**Run the cell below to save the state of your model. You will be required to upload `best_cnn_model.pt` and the `cnn.py` file to Gradescope for accuracy evaluation. You must reach an accuracy of >= 50% on the above test dataset to receive credit for this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "86a318d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "XwwCsXxux2nS",
    "outputId": "7b88e6a6-9122-4ed7-a223-c7892856f9b7"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "torch.save(model.state_dict(), 'best_cnn_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1fc62e",
   "metadata": {
    "id": "hJaO3vd_oP-Z"
   },
   "source": [
    "## Q3: Classification with RNN [15pts]\n",
    "\n",
    "In this section we will be using recurrent neural networks for classification. Below is a diagram of our model architecture, note how the hidden state of the last word in the forward direction and the hidden state of the first word in the reverse direction are both fed into the dense linear layer.\n",
    "\n",
    "<p align=\"center\"><img src=\"https://www.tensorflow.org/static/text/tutorials/images/bidirectional.png\" width=\"75%\" align=\"center\"></p>\n",
    "\n",
    "We will be using an embedding layer, followed by a bi-directional RNN layer, and then a linear layer.\n",
    "\n",
    "We will use the Clickbait and Web of Science dataset for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6fd74",
   "metadata": {
    "id": "alo7oi32yrwp"
   },
   "source": [
    "## 3.1: Implementing RNN Classifier [10pts]\n",
    "In the **rnn.py** file complete the following functions:\n",
    "  * <strong>\\_\\_init__</strong>\n",
    "  * <strong>forward_embed</strong>\n",
    "  * <strong>forward_rnn</strong>\n",
    "  * <strong>forward_concat</strong>\n",
    "  * <strong>forward</strong>\n",
    "\n",
    "We have included local tests in 3.2.2 for you to test your implementation of the RNN functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd44755",
   "metadata": {
    "id": "Aajl3628zAkp"
   },
   "source": [
    "### 3.1.1: Pre-Processing Data [No Points]\n",
    "\n",
    "Run the below cells to load functions for building vocabulary and tokenizing the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d9fe570",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "8qk1qpnIzCwe",
    "outputId": "5f75fc50-8aaa-4a09-dc2e-f78bcc8ed8d3"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def build_vocabulary(datasets):\n",
    "    for dataset in datasets:\n",
    "        for text in dataset:\n",
    "            yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(build_vocabulary([x_train]), min_freq=1, specials=[\"<UNK>\"])\n",
    "vocab.set_default_index(vocab[\"<UNK>\"])\n",
    "\n",
    "vocab_wos = build_vocab_from_iterator(build_vocabulary([x_train_wos]), min_freq=1, specials=[\"<UNK>\"])\n",
    "vocab_wos.set_default_index(vocab[\"<UNK>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144337fd",
   "metadata": {},
   "source": [
    "## 3.2: Classifying Clickbait Dataset using RNN [5pts]\n",
    "\n",
    "Run the cells below to classify the Clickbait train and test dataset using the RNN functions that you have implemented. \n",
    "\n",
    "**You must reach an accuracy of >= 85% to receive credit for this section.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f48a4",
   "metadata": {},
   "source": [
    "### 3.2.1 : Create the Dataloaders [No Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58fcc478",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "max_words = 0\n",
    "for t in x_train:\n",
    "    max_words = max(max_words, len(vocab(tokenizer(t))))\n",
    "\n",
    "def vectorize_batch(batch):\n",
    "    Y, X = list(zip(*batch))\n",
    "    X = [vocab(tokenizer(text)) for text in X] ## Tokenize and map tokens to indexes\n",
    "    X_len = [len(text) for text in X]\n",
    "    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] ## Bringing all samples to max_words length.\n",
    "    return torch.tensor(X, dtype=torch.int32), torch.tensor(X_len), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "644a3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "train_dataset = list(map(lambda y, x: (y, x), y_train, x_train))\n",
    "test_dataset = list(map(lambda y, x: (y, x), y_test, x_test))\n",
    "\n",
    "# Uncomment for use if there is a discrepancy in testing accuracy between notebook and gradescope\n",
    "# train_dataset = torch.load('./data/rnn_train_dataset_cb.pt')\n",
    "# test_dataset = torch.load('./data/rnn_test_dataset_cb.pt')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, collate_fn=vectorize_batch, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=1024, collate_fn=vectorize_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15966713",
   "metadata": {},
   "source": [
    "### 3.2.2: Local Tests for RNN Functions [No Points]\n",
    "You may test your implementation of the functions contained in **rnn.py** in the cell below. Feel free to comment out tests for functions that have not been completed yet. See [Using the Local Tests](#using_local_tests) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ad9adb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Tests for RNN Implementation \n",
      "\n",
      "Your forward_embed works as expected: True\n",
      "Your forward_rnn works as expected: True\n",
      "Your forward_concat works as expected: True\n",
      "Your forward works as expected: True\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from rnn import RNN\n",
    "from local_tests.rnn_test import RNN_Test\n",
    "torch.manual_seed(10)\n",
    "\n",
    "local_test = RNN_Test()\n",
    "rnn_model = RNN(vocab, num_classes=2)\n",
    "rnn_model.load_state_dict(torch.load('./local_tests/basic_rnn_model.pt'))    # upload default weights. If this errors out, make sure you have initialized the layers correctly.\n",
    "rnn_model.eval()\n",
    "\n",
    "# creating a vectorized batch from the sample datapoints\n",
    "local_test_dataset = list(map(lambda y, x: (y, x), local_test.output_labels, local_test.input_sequences))\n",
    "X_localtest, X_len_localtest, Y_localtest = vectorize_batch(local_test_dataset)\n",
    "\n",
    "print('Local Tests for RNN Implementation \\n')\n",
    "\n",
    "# Local test for forward_embed\n",
    "embeddings = rnn_model.forward_embed(X_localtest)\n",
    "forward_embed_test = (embeddings.shape == local_test.embeddings.shape) and (torch.allclose(embeddings, local_test.embeddings, rtol=0.0001, atol=0.0001))\n",
    "print('Your forward_embed works as expected:', forward_embed_test)\n",
    "\n",
    "# Local test for forward_rnn\n",
    "rnn_output = rnn_model.forward_rnn(local_test.embeddings, X_len_localtest)\n",
    "forward_rnn_test = (rnn_output.shape == local_test.rnn_output.shape) and (torch.allclose(rnn_output, local_test.rnn_output, rtol=0.0001, atol=0.0001))\n",
    "print('Your forward_rnn works as expected:', forward_rnn_test)\n",
    "\n",
    "# Local test for forward_concat\n",
    "concat = rnn_model.forward_concat(local_test.rnn_output, X_len_localtest)\n",
    "forward_concat_test = (concat.shape == local_test.concat.shape) and (torch.allclose(concat, local_test.concat))\n",
    "print('Your forward_concat works as expected:', forward_concat_test)\n",
    "\n",
    "# Local test for forward\n",
    "output = rnn_model.forward(X_localtest, X_len_localtest)\n",
    "forward_test = (output.shape == local_test.output.shape) and (torch.allclose(output, local_test.output, rtol=0.0001, atol=0.0001))\n",
    "print('Your forward works as expected:', forward_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f7c026",
   "metadata": {},
   "source": [
    "### 3.2.3: Train and Evaluate on the Clickbait Dataset [5pts]\n",
    "\n",
    "**You must reach an accuracy of >= 85% to receive credit for this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8bfe6394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for running: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bdbbf65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "zlXccqKokN-u",
    "outputId": "bc849b0f-43ad-4783-f8ad-da88656026d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 0: 7.425033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 1: 2.568353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 2: 1.059574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 3: 0.366320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 4: 0.108225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from rnn import RNN\n",
    "from tqdm import tqdm\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "model = RNN(vocab, num_classes=NUM_CLASSES)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "N_EPOCHS = 5\n",
    "\n",
    "model.train()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for X, X_len, Y in tqdm(train_loader):\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        outputs = model(X, X_len)\n",
    "        loss = criterion(outputs, Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbf636e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "UjopZ85QsEcV",
    "outputId": "bac143d6-28f5-4f83-a18f-b00176d82080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on Clickbait Dataset using RNN  : 0.970\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_truth, Y_preds = [],[]\n",
    "    for X, X_len, Y in test_loader:\n",
    "        X = X.to(device)\n",
    "        outputs = model(X, X_len)\n",
    "\n",
    "        Y_truth.append(Y)\n",
    "        Y_preds.append(outputs)\n",
    "\n",
    "        break\n",
    "\n",
    "    Y_truth = torch.cat(Y_truth)\n",
    "    Y_preds = torch.cat(Y_preds)\n",
    "\n",
    "print(\"Test Accuracy on Clickbait Dataset using RNN  : {:.3f}\".format(accuracy_score(Y_truth.cpu().detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5edefb",
   "metadata": {
    "id": "i7JXqy4Yzj7R"
   },
   "source": [
    "### ðŸ¦‰ <font color='darkred'>Submit these files to Gradescope</font>\n",
    "**Run the cell below to save the state of your model. You will be required to upload `best_rnn_model.pt` and the `rnn.py` file to Gradescope for accuracy evaluation. You must reach an accuracy of >= 85% on the above test dataset to receive credit for this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aff59340",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "YIoYfQJtzkdX",
    "outputId": "81b2dfae-81e3-4576-d8e9-58e6e6a0647a"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "torch.save(model.state_dict(), 'best_rnn_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70430472",
   "metadata": {
    "id": "_sW4Am9kvdGA"
   },
   "source": [
    "## 3.3: Classifying Web of Science Dataset using RNN [No Points]\n",
    "\n",
    "Run the cells below to classify the WoS train and test dataset using the RNN functions that you have already implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319fefdc",
   "metadata": {},
   "source": [
    "### 3.3.1: Create the Dataloaders [No Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56950773",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "DPZE5g1uRI_I",
    "outputId": "5b47c0ad-5e17-4424-c482-2d102e746fbe"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "max_words = 0\n",
    "for t in x_train_wos:\n",
    "    max_words = max(max_words, len(vocab_wos(tokenizer(t))))\n",
    "\n",
    "def vectorize_batch(batch):\n",
    "    Y, X = list(zip(*batch))\n",
    "    X = [vocab_wos(tokenizer(text)) for text in X] ## Tokenize and map tokens to indexes\n",
    "    X_len = [len(text) for text in X]\n",
    "    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] \n",
    "    return torch.tensor(X, dtype=torch.int32), torch.tensor(X_len), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47453368",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "1ypsgOIIRUFm",
    "outputId": "6c795bf1-88db-46e4-ec3e-606d7aaf0dfb"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "train_dataset = list(map(lambda y, x: (y, x), y_train_wos, x_train_wos))\n",
    "test_dataset = list(map(lambda y, x: (y, x), y_test_wos, x_test_wos))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, collate_fn=vectorize_batch, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=128, collate_fn=vectorize_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbcebe9",
   "metadata": {},
   "source": [
    "### 3.3.2: Train and Evaluate on the Web of Science dataset [No Points]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df8afa7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "id": "195yI5vSvhWr",
    "outputId": "1b605091-1ba2-4735-df9d-3f53477f8403",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:40<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 0: 17.743953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:37<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 1: 16.561113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:36<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 2: 15.769293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:35<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 3: 15.255360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:31<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 4: 14.698310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:29<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 5: 14.084519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:29<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 6: 13.353101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:29<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 7: 12.664914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:28<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 8: 11.803915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:31<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 9: 10.981505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:27<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 10: 9.964871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:28<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 11: 8.901491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:27<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 12: 7.992615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:28<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 13: 6.986914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:26<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 14: 6.170211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:27<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 15: 5.363673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:28<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 16: 4.700289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:27<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 17: 4.215163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:27<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 18: 3.766051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:26<00:00,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 19: 3.070051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from rnn import RNN\n",
    "from tqdm import tqdm\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "model = RNN(vocab_wos, num_classes=NUM_CLASSES)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "N_EPOCHS = 20\n",
    "\n",
    "model.train()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for X, X_len, Y in tqdm(train_loader):\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        outputs = model(X, X_len)\n",
    "        loss = criterion(outputs, Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "475a2dba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ltNFDxdyvt-k",
    "outputId": "f9f407e2-4540-4955-c8db-b4b5543e1eb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on WoS Dataset using RNN  : 0.490\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_truth, Y_preds = [],[]\n",
    "    for X, X_len, Y in test_loader:\n",
    "        X = X.to(device)\n",
    "        outputs = model(X, X_len)\n",
    "\n",
    "        Y_truth.append(Y)\n",
    "        Y_preds.append(outputs)\n",
    "\n",
    "    Y_truth = torch.cat(Y_truth)\n",
    "    Y_preds = torch.cat(Y_preds)\n",
    "\n",
    "print(\"Test Accuracy on WoS Dataset using RNN  : {:.3f}\".format(accuracy_score(Y_truth.cpu().detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228f8400",
   "metadata": {
    "id": "Kb6rhadO0UEq"
   },
   "source": [
    "**NOTE** : RNN alone is not able to perform well on the WoS dataset and that can be attributed to the very limited data with large vocabulary and lack of embedding structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d90e03",
   "metadata": {},
   "source": [
    "## Q4: Classification with NN [3.75pts Bonus Extra Credit]\n",
    "\n",
    "You may have noticed that both CNN and RNN did not perform as well on the Web of Science dataset as other machine learning algorithms that we explored in previous homeworks. It is possible that the limited dataset compared to the complexity of the CNN and RNN network was not sufficient to train these networks to a high enough accuracy. In this bonus question, we ask you to explore how a two layer neural net would fare on the Web of Science dataset. You will need to implement a two layer neural net using pytorch's linear layers as well as write your own training loop to train your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d6379",
   "metadata": {},
   "source": [
    "### 4.1: Implementing NN Classifier [1.25 pts Bonus Extra Credit]\n",
    "Implement your two layer neural net. We require your model to have exactly two linear layers to pass the autograder and that you adhere to the specified input and output shapes. You are free to design the rest of your network as you see fit and use any non-linearity or dropout layers to obtain the necessary accuracy.\n",
    "\n",
    "In the **nn.py** file complete the following functions:\n",
    "  * <strong>\\_\\_init__</strong>\n",
    "  * <strong>forward</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec4b13",
   "metadata": {},
   "source": [
    "### 4.2: Local Tests for NN Functions [No Points]\n",
    "You may test your implementation of the functions contained in **nn.py** in the cell below. Feel free to comment out tests for functions that have not been completed yet. See [Using the Local Tests](#using_local_tests) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "272e0d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Tests for NN Implementation \n",
      "\n",
      "Your forward accepts and outputs the expected shapes: True\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from nn import NN\n",
    "from local_tests.nn_test import NN_Test\n",
    "\n",
    "local_test = NN_Test()\n",
    "sample_input = torch.cat([torch.tensor(sample_input[0]).unsqueeze(0) for sample_input in torch.load('./data/bonus_train_wos.pt')[:3]])\n",
    "nn_model = NN(feat_size = sample_input.shape[-1], num_classes=4)\n",
    "\n",
    "print('Local Tests for NN Implementation \\n')\n",
    "\n",
    "# Local test for forward\n",
    "output = nn_model.forward(sample_input)\n",
    "forward_test = (output.shape == local_test.sample_output.shape)\n",
    "print('Your forward accepts and outputs the expected shapes:', forward_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f706bd",
   "metadata": {},
   "source": [
    "### 4.3: Loading and Preprocessing the Web of Science Dataset [No Points]\n",
    "For this exercise, we will use sklearn's TFIDF Vectorizer to encode and then PCA to reduce the dimensionality of the Web of Science dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5eaebc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# This cell may take a minute or so to run\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Encode the Web of Science dataset using TFIDF\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', stop_words='english')\n",
    "x_train_tfidf_wos = tfidf_vect.fit_transform(x_train_wos).toarray()\n",
    "x_test_tfidf_wos = tfidf_vect.transform(x_test_wos).toarray()\n",
    "\n",
    "# Reduce the dimensionality of the encoded dataset \n",
    "pca = PCA(n_components=1024)\n",
    "pca.fit(x_train_tfidf_wos)\n",
    "x_train_wos_pca = pca.transform(x_train_tfidf_wos).astype('float32')\n",
    "x_test_wos_pca = pca.transform(x_test_tfidf_wos).astype('float32')\n",
    "\n",
    "train_dataset = list(zip(x_train_wos_pca, y_train_wos)) \n",
    "test_dataset = list(zip(x_test_wos_pca, y_test_wos)) \n",
    "\n",
    "# Uncomment for use if there is a discrepancy in testing accuracy between notebook and gradescope\n",
    "# train_dataset = torch.load('./data/bonus_train_wos.pt')\n",
    "# test_dataset = torch.load('./data/bonus_test_wos.pt')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128,  shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b0fa8",
   "metadata": {},
   "source": [
    "### 4.4: Training Your Model & Testing Accuracy [2.5pts Bonus Extra Credit]\n",
    "Here you will write your own training loop. You are free to decide on the criterion, optimizer, and various hyperparameters required for training. Keep in mind that you are building a classifier and some criterions are more suited for this task than others. Your model must be able to accept the data from train_loader and output the expected shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "961df587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import NN\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "feat_size = train_dataset[0][0].shape[0]\n",
    "model = NN(feat_size, num_classes=NUM_CLASSES)\n",
    "\n",
    "# TODO: Write your own training loop using train_loader. You will need to choose a criterion and optimizer. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af559884",
   "metadata": {},
   "source": [
    "After you have trained your model, run the below cell to see how your trained model performs with the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "283b37dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on WoS Dataset using NN  : 0.250\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_truth, Y_preds = [],[]\n",
    "    for X, Y in test_loader:\n",
    "        X = X.to(device)\n",
    "        outputs = model(X)\n",
    "\n",
    "        Y_truth.append(Y)\n",
    "        Y_preds.append(outputs)\n",
    "\n",
    "    Y_truth = torch.cat(Y_truth)\n",
    "    Y_preds = torch.cat(Y_preds)\n",
    "\n",
    "curr_acc_score = accuracy_score(Y_truth.cpu().detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy())\n",
    "print(\"Test Accuracy on WoS Dataset using NN  : {:.3f}\".format(curr_acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a098801f",
   "metadata": {},
   "source": [
    "### ðŸ¦¥ <font color='darkred'>Submit these files to Gradescope</font>\n",
    "**Run the cell below to save the state of your model. You will be required to upload `best_nn_model.pt` and the `nn.py` file to Gradescope for accuracy evaluation. You must reach an accuracy of >= 80% on the above test dataset to receive credit for this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ac863840",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "torch.save(model.state_dict(), 'best_nn_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fb1621",
   "metadata": {},
   "source": [
    "**Congrats, you have reached the end of Homework 3 ðŸ˜Ž**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-Np3UUmtFUjd",
    "4TLUiFFR7wlL",
    "dRvybL9rYxcQ",
    "_sW4Am9kvdGA"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
